<p>The difference lies in the observability of the states and how they relate to the observations:</p>

<ul>
  <li><strong>Markov Model (MM)</strong>: <strong><em>States are directly observable</em></strong>, and each state transition corresponds to an observable event. The model focuses on state transitions.</li>
  <li><strong>Hidden Markov Model (HMM)</strong>: <strong><em>States are hidden and not directly observable.</em></strong> Each state can produce observable outputs, but these outputs do not have a one-to-one correspondence with the states, introducing a level of uncertainty about the actual state, which must be inferred from the observations.</li>
</ul>

<p>HMM are especially known for applications in <strong><em>temporal pattern recognition</em></strong>.</p>

<h5 id="hmm-operation">HMM Operation</h5>

<p>For $H = {N, M, A, B, \pi}$, $H$ can be used as a genenrator for an observation sequence, $O = O_1, O_2, O_3, …, O_T$, where each observation $O_t$ is a symbol from $V$, and $T$ is the number of observations in the sequence as follows.</p>

<ol>
  <li>Choose an initial state $q_1 = S_i$ according to the initial state distribution $\pi$.</li>
  <li>Set $t=1$.</li>
  <li>Choose $O_t = v_k$ according to the observation symbol probability distribution in state $S_i$ as determined by $b_j(k)$. (generate a observation based on the distribution of $B$)</li>
  <li>Transition to state $q_{t+1}=S_j$ according to the state transition probability distribution for state $S_i$ as determined by ${a_{ij}}$.</li>
  <li>Return to step 3, if $t&lt;T$; otherwise, <strong>terminate</strong>.</li>
</ol>

<p>3 basic problems need to be solved for a model to be used in real-world applications.</p>

<ol>
  <li>
    <table>
      <tbody>
        <tr>
          <td>Given the observation sequence $O=O_1,…,O_t$ and a model $\lambda= (A, B, \pi)$, how do we efficiently compute $P(O</td>
          <td>\lambda)$​.</td>
        </tr>
      </tbody>
    </table>
    <ol>
      <li>brute force:
        <ol>
          <li>
            <table>
              <tbody>
                <tr>
                  <td>We can obtain the distribution of $P(O</td>
                  <td>Q, \lambda) = \prod b_q(O)$</td>
                </tr>
              </tbody>
            </table>
          </li>
          <li>
            <table>
              <tbody>
                <tr>
                  <td>We can obtain the distribution of $P(Q</td>
                  <td>\lambda) = \pi \prod a_{i, i+1}$</td>
                </tr>
              </tbody>
            </table>
          </li>
          <li>
            <table>
              <tbody>
                <tr>
                  <td>$P(O</td>
                  <td>\lambda) = P(O</td>
                  <td>Q, \lambda) P(Q</td>
                  <td>\lambda)$​ (joint probability)</td>
                </tr>
              </tbody>
            </table>
          </li>
          <li>not efficient! (take exponetial times to calculate)</li>
        </ol>
      </li>
      <li>forward-backward procedure:
        <ol>
          <li>$\alpha$</li>
        </ol>
      </li>
    </ol>
  </li>
  <li>Given the observation sequence and model, how do we choose a corresponding state sequence $Q=q_1q_2 … q_T$ that is optimal in some meaningful sense. (attempting to uncover the hidden part)</li>
  <li>
    <table>
      <tbody>
        <tr>
          <td>Given the observation sequence and model, how do we adjust the model parameters $A, B$ and $\pi$ to maximize $P(O</td>
          <td>\lambda)$.</td>
        </tr>
      </tbody>
    </table>
  </li>
</ol>

<p>The observation sequence used to adjust the model parameters is called a training sequence since it is used to train the HMM.</p>

<p>Solutions to these problems.</p>

